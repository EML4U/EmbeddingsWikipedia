{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings for wikipedia texts\n",
    "# Note: Embeddings computation for   20x2 texts takes around   23 seconds on the EML4U experiment server.\n",
    "#       \"                          3596x2 texts \"             3396 seconds \"\n",
    "#       In 1 hour you can process around 3,600 = 60*60 text-pairs.\n",
    "\n",
    "baseDir = \"/home/eml4u/EML4U/notebooks/wilke\"\n",
    "\n",
    "idA = \"20100408-american-films\"\n",
    "idB = \"20201101-american-films\"\n",
    "if False:\n",
    "    idA = \"20100408-british-films\"\n",
    "    idB = \"20201101-british-films\"\n",
    "if False:\n",
    "    idA = \"20100408-indian-films\"\n",
    "    idB = \"20201101-indian-films\"\n",
    "dataDirA = \"/home/eml4u/EML4U/data/corpus/2021-02-10-wikipedia-texts/\" + idA + \"/\"\n",
    "dataDirB = \"/home/eml4u/EML4U/data/corpus/2021-02-10-wikipedia-texts/\" + idB + \"/\"\n",
    "\n",
    "outDir = \"/home/eml4u/EML4U/data/interim-results/\"\n",
    "fileEmbeddingsA = outDir + idA + \".txt\"\n",
    "fileEmbeddingsB = outDir + idB + \".txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file paths (second variant: limit number of files)\n",
    "import glob\n",
    "filesA = glob.glob(dataDirA + '*.txt')\n",
    "filesB = glob.glob(dataDirB + '*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit number of file paths (e.g. for tests)\n",
    "if True:\n",
    "    filesA = filesA[:20]\n",
    "    filesB = filesB[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print file paths (to check if equal)\n",
    "if False:\n",
    "    print('\\n'.join(map(str, filesA)))\n",
    "    print()\n",
    "    print('\\n'.join(map(str, filesB)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read files\n",
    "textsA = []\n",
    "for filename in filesA:\n",
    "    fileobject = open(filename, \"r\") \n",
    "    text = fileobject.read()\n",
    "    textsA.append(text)\n",
    "    fileobject.close\n",
    "\n",
    "textsB = []\n",
    "for filename in filesB:\n",
    "    fileobject = open(filename, \"r\") \n",
    "    text = fileobject.read()\n",
    "    textsB.append(text)\n",
    "    fileobject.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# Print texts\n",
    "print(len(textsA))\n",
    "print(len(textsB))\n",
    "\n",
    "if False:\n",
    "    print(textsA[0])\n",
    "    print(textsB[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Prepare embeddings\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(baseDir))\n",
    "from embedding import BertHuggingface\n",
    "\n",
    "NUM_CLASSES = 8 # irrelevant if you dont want to retrain\n",
    "bert = BertHuggingface(NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 22.90404772758484 seconds\n",
      "embeddingsA.shape: (20, 768)\n",
      "embeddingsB.shape: (20, 768)\n"
     ]
    }
   ],
   "source": [
    "# Create embeddings\n",
    "import time\n",
    "startTime = time.time()\n",
    "embeddingsA = bert.embed(textsA)\n",
    "embeddingsB = bert.embed(textsB)\n",
    "\n",
    "print(\"Runtime: %s seconds\" % (time.time() - startTime))\n",
    "print(\"embeddingsA.shape:\", embeddingsA.shape)\n",
    "print(\"embeddingsB.shape:\", embeddingsB.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eml4u/EML4U/data/interim-results/20100408-american-films.txt\n",
      "/home/eml4u/EML4U/data/interim-results/20201101-american-films.txt\n"
     ]
    }
   ],
   "source": [
    "# Write embeddings/arrays to files\n",
    "import numpy\n",
    "numpy.savetxt(fileEmbeddingsA, embeddingsA)\n",
    "numpy.savetxt(fileEmbeddingsB, embeddingsB)\n",
    "print(fileEmbeddingsA)\n",
    "print(fileEmbeddingsB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Check: Load arrays\n",
    "if True:\n",
    "    loadedA = numpy.loadtxt(fileEmbeddingsA)\n",
    "    loadedB = numpy.loadtxt(fileEmbeddingsB)\n",
    "    print(numpy.array_equal(embeddingsA, loadedA))\n",
    "    print(numpy.array_equal(embeddingsB, loadedB))\n",
    "    print(type(embeddingsA))\n",
    "    print(type(loadedA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (EML4U)",
   "language": "python",
   "name": "eml4u"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
