{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check installation\n",
    "# https://jakevdp.github.io/blog/2017/12/05/installing-python-packages-from-jupyter/\n",
    "#!type -a python\n",
    "#!type -a conda\n",
    "#!type -a pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation\n",
    "# https://stackoverflow.com/a/1472014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The installation was finalized by local conda commands.\n",
    "# requirements.txt does not contain all required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "#import sklearsklearn.metrics.pairwise\n",
    "\n",
    "#sys.path.append(os.path.abspath('/home/eml4u/EML4U/notebooks/wilke'))\n",
    "from embedding import BertHuggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the embeddings: (3, 768)\n"
     ]
    }
   ],
   "source": [
    "# From examples/huggingface_basic.py\n",
    "\n",
    "# Variables\n",
    "NUM_CLASSES = 8 # irrelevant if you dont want to retrain\n",
    "sentences = [\n",
    "    \"Hello, this is a test for the Huggingface Bert.\",\n",
    "    \"Did you know the Huggingface library was named after the smiley?\",\n",
    "    \"Hello, this is a test of the Huggingface Bert.\",    \n",
    "]\n",
    "\n",
    "# embedding\n",
    "bert = BertHuggingface(NUM_CLASSES)\n",
    "embeddings = bert.embed(sentences)\n",
    "\n",
    "print(\"Shape of the embeddings:\", embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 768)\n",
      "\n",
      "0.08651745\n",
      "0.10559316\n",
      "0.06962866\n",
      "0.08724642793337505\n",
      "\n",
      "0.087246425\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(embeddings, axis=0).reshape(1, 768)\n",
    "print(mean.shape)\n",
    "print()\n",
    "\n",
    "print(embeddings[0][0])\n",
    "print(embeddings[1][0])\n",
    "print(embeddings[2][0])\n",
    "print((embeddings[0][0] + embeddings[1][0] + embeddings[2][0])/3)\n",
    "print()\n",
    "\n",
    "print(mean[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9721441]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.pairwise.cosine_similarity(embeddings[0].reshape(1, -1), embeddings[2].reshape(1, -1), dense_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.72853875]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.pairwise.cosine_similarity(embeddings[0].reshape(1, -1), embeddings[1].reshape(1, -1), dense_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (EML4U)",
   "language": "python",
   "name": "eml4u"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

